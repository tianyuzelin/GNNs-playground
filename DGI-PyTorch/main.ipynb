{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "907c7959-33a3-4547-9cf2-9fb67ad36d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This model is currently unusable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72f55cbb-676d-4c64-9653-64a1ce92f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "082c6237-fbcc-4aad-a437-e46e0fb8fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_h):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.f_k = nn.Bilinear(n_h, n_h, 1)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Bilinear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, c, h_pl, h_mi, s_bias1=None, s_bias2=None):\n",
    "        c_x = torch.unsqueeze(c, 1)\n",
    "        c_x = c_x.expand_as(h_pl)\n",
    "\n",
    "        sc_1 = torch.squeeze(self.f_k(h_pl, c_x), 2)\n",
    "        sc_2 = torch.squeeze(self.f_k(h_mi, c_x), 2)\n",
    "\n",
    "        if s_bias1 is not None:\n",
    "            sc_1 += s_bias1\n",
    "        if s_bias2 is not None:\n",
    "            sc_2 += s_bias2\n",
    "\n",
    "        logits = torch.cat((sc_1, sc_2), 1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "715f89d8-e49e-435c-99ed-400b167799ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_ft, out_ft, act, bias=True):\n",
    "        super(GCN, self).__init__()\n",
    "        self.fc = nn.Linear(in_ft, out_ft, bias=False)\n",
    "        self.act = nn.PReLU() if act == 'prelu' else act\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.FloatTensor(out_ft))\n",
    "            self.bias.data.fill_(0.0)\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    # Shape of seq: (batch, nodes, features)\n",
    "    def forward(self, seq, adj, sparse=False):\n",
    "        seq_fts = self.fc(seq)\n",
    "        if sparse:\n",
    "            out = torch.unsqueeze(torch.spmm(adj, torch.squeeze(seq_fts, 0)), 0)\n",
    "        else:\n",
    "            out = torch.bmm(adj, seq_fts)\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        \n",
    "        return self.act(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca6038b6-d900-47f9-8b6c-3880877c74f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgReadout(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AvgReadout, self).__init__()\n",
    "\n",
    "    def forward(self, seq, msk):\n",
    "        if msk is None:\n",
    "            return torch.mean(seq, 1)\n",
    "        else:\n",
    "            msk = torch.unsqueeze(msk, -1)\n",
    "            return torch.sum(seq * msk, 1) / torch.sum(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1e4d4c6-64a6-4112-b5bb-ad6c26e094d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg(nn.Module):\n",
    "    def __init__(self, ft_in, nb_classes):\n",
    "        super(LogReg, self).__init__()\n",
    "        self.fc = nn.Linear(ft_in, nb_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            self.weights_init(m)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.xavier_uniform_(m.weight.data)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, seq):\n",
    "        ret = self.fc(seq)\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a95c2f6-12d6-49e8-8edb-55f567a48e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGI(nn.Module):\n",
    "    def __init__(self, n_in, n_h, activation):\n",
    "        super(DGI, self).__init__()\n",
    "        self.gcn = GCN(n_in, n_h, activation)\n",
    "        self.read = AvgReadout()\n",
    "\n",
    "        self.sigm = nn.Sigmoid()\n",
    "\n",
    "        self.disc = Discriminator(n_h)\n",
    "\n",
    "    def forward(self, seq1, seq2, adj, sparse, msk, samp_bias1, samp_bias2):\n",
    "        h_1 = self.gcn(seq1, adj, sparse)\n",
    "\n",
    "        c = self.read(h_1, msk)\n",
    "        c = self.sigm(c)\n",
    "\n",
    "        h_2 = self.gcn(seq2, adj, sparse)\n",
    "\n",
    "        ret = self.disc(c, h_1, h_2, samp_bias1, samp_bias2)\n",
    "\n",
    "        return ret\n",
    "\n",
    "    # Detach the return variables\n",
    "    def embed(self, seq, adj, sparse, msk):\n",
    "        h_1 = self.gcn(seq, adj, sparse)\n",
    "        c = self.read(h_1, msk)\n",
    "\n",
    "        return h_1.detach(), c.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643237f9-e528-463f-a289-316420808529",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
